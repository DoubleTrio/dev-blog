<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="TheKaceFiles">
<meta name="dcterms.date" content="2025-06-07">
<meta name="description" content="General notes on how audio and pitch works in Blender’s VSE">

<title>Understanding VSE Audio in the Sequencer – GSOC 2025 - Pitch Correction for Sound Playback in Sequencer Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/videojs/video.min.js"></script>
<link href="../../site_libs/quarto-contrib/videojs/video-js.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">GSOC 2025 - Pitch Correction for Sound Playback in Sequencer Blog</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Understanding VSE Audio in the Sequencer</h1>
                  <div>
        <div class="description">
          General notes on how audio and pitch works in Blender’s VSE
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">blender</div>
                <div class="quarto-category">c++</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>TheKaceFiles </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 7, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>This week, I have been taking the time to understand how Audaspace is integrated into Blender’s VSE. The most important files are <code>blenkernel/intern/sound.cc</code> and its header file <code>blenkernel/BKE_sound.h</code>. I will taking a little look at specifically animating sound properties (eg. volume and pitch) which <code>@iss</code> or Richard Antalik describes in the following <a href="https://devtalk.blender.org/t/gsoc-2025-draft-pitch-correction-for-sound-playback-in-sequencer/39752">thread</a>. Furthermore, <code>@neYyon</code> or Jörg Müller gave tips on how to integrate the Rubber Band Library into Audaspace <a href="https://devtalk.blender.org/t/gsoc-2025-pitch-correction-for-sound-playback/40371/2?u=thekacefiles">here</a>.</p>
<section id="playing-audio" class="level2">
<h2 class="anchored" data-anchor-id="playing-audio">Playing Audio</h2>
<p>When you press <code>Spacebar</code> to play an audio clip in the sequencer, the <code>BKE_sound_play_scene</code> function is called, which makes several calls to the Audaspace library below.</p>
<details>
<summary>
Code
</summary>
<pre class="{cpp}"><code>
  // Called by `wmOperatorStatus ED_screen_animation_play(bContext *C, int sync, int mode)` in `screen_cops.cc`
  void BKE_sound_play_scene(Scene *scene)
  {
    std::lock_guard lock(g_state.sound_device_mutex);
    sound_device_use_begin();
    sound_verify_evaluated_id(&amp;scene-&gt;id);

    AUD_Status status;
    const double cur_time = get_cur_time(scene);

    AUD_Device_lock(g_state.sound_device);

    if (scene-&gt;sound_scrub_handle &amp;&amp;
        AUD_Handle_getStatus(scene-&gt;sound_scrub_handle) != AUD_STATUS_INVALID)
    {
      /* If the audio scrub handle is playing back, stop to make sure it is not active.
      * Otherwise, it will trigger a callback that will stop audio playback. */
      AUD_Handle_stop(scene-&gt;sound_scrub_handle);
      scene-&gt;sound_scrub_handle = nullptr;
      /* The scrub_handle started playback with playback_handle, stop it so we can
      * properly restart it. */
      AUD_Handle_pause(scene-&gt;playback_handle);
    }

    status = scene-&gt;playback_handle ? AUD_Handle_getStatus(scene-&gt;playback_handle) :
                                      AUD_STATUS_INVALID;

    if (status == AUD_STATUS_INVALID) {
      sound_start_play_scene(scene);

      if (!scene-&gt;playback_handle) {
        AUD_Device_unlock(g_state.sound_device);
        return;
      }
    }

    if (status != AUD_STATUS_PLAYING) {
      /* Seeking the synchronizer will also seek the playback handle.
      * Even if we don't have A/V sync on, keep the synchronizer and handle seek time in sync. */
      AUD_seekSynchronizer(cur_time);
      AUD_Handle_setPosition(scene-&gt;playback_handle, cur_time);
      AUD_Handle_resume(scene-&gt;playback_handle);
    }

    if (scene-&gt;audio.flag &amp; AUDIO_SYNC) {
      AUD_playSynchronizer();
    }

    AUD_Device_unlock(g_state.sound_device);
  }</code></pre>
</details>
</section>
<section id="animating-audio" class="level2">
<h2 class="anchored" data-anchor-id="animating-audio">Animating Audio</h2>
<p>There are currently 5 properties of audio that can be animated in Audiospace shown below:</p>
<details>
<summary>
Code
</summary>
<pre class="{c++}"><code>AnimateableProperty* SequenceEntry::getAnimProperty(AnimateablePropertyType type)
{
    switch(type)
    {
    case AP_VOLUME:
        return &amp;m_volume;
    case AP_PITCH:
        return &amp;m_pitch;
    case AP_PANNING:
        return &amp;m_panning;
    case AP_LOCATION:
        return &amp;m_location;
    case AP_ORIENTATION:
        return &amp;m_orientation;
    default:
        return nullptr;
    }
}</code></pre>
</details>
<p>We’ll be looking at in particular how the <strong>volume</strong> and <strong>pitch</strong> is animated in Blender’s VSE.</p>
</section>
<section id="volume" class="level2">
<h2 class="anchored" data-anchor-id="volume">Volume</h2>
<section id="caution-volume-warning" class="level3">
<h3 class="anchored" data-anchor-id="caution-volume-warning"><strong>(CAUTION: VOLUME WARNING)</strong></h3>
<div id="fig-my-video" class="quarto-float quarto-figure quarto-figure-center anchored" alt="Clip of adjusting the volume ">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-my-video-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video"><video id="video_shortcode_videojs_video1" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="volume_example.mp4"></video></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-my-video-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1
</figcaption>
</figure>
</div>
<!-- ![Volume](volume_property.png) -->
<p>The RNA for the volume property is defined <code>rna_sequencer.cc</code> in the function <code>rna_def_audio_options</code></p>
<details>
<summary>
Code
</summary>
<pre class="{c++}"><code>static void rna_def_audio_options(StructRNA *srna)
{
  PropertyRNA *prop;

  prop = RNA_def_property(srna, "volume", PROP_FLOAT, PROP_NONE);
  RNA_def_property_float_sdna(prop, nullptr, "volume");
  RNA_def_property_range(prop, 0.0f, 100.0f);
  RNA_def_property_float_default(prop, 1.0f);
  RNA_def_property_ui_text(prop, "Volume", "Playback volume of the sound");
  RNA_def_property_translation_context(prop, BLT_I18NCONTEXT_ID_SOUND);
  RNA_def_property_update(prop, NC_SCENE | ND_SEQUENCER, "rna_Strip_audio_update");
}</code></pre>
</details>
<p>And the UI for the volume (or the sound properties) is defined in <code>space_sequencer.py</code></p>
<div id="c6e64de0" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw(<span class="va">self</span>, context):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        layout <span class="op">=</span> <span class="va">self</span>.layout</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        st <span class="op">=</span> context.space_data</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        overlay_settings <span class="op">=</span> st.timeline_overlay</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        strip <span class="op">=</span> context.active_strip</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        sound <span class="op">=</span> strip.sound</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        layout.active <span class="op">=</span> <span class="kw">not</span> strip.mute</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> sound <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>            layout.use_property_split <span class="op">=</span> <span class="va">True</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>            col <span class="op">=</span> layout.column()</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            split <span class="op">=</span> col.split(factor<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>            split.alignment <span class="op">=</span> <span class="st">'RIGHT'</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            split.label(text<span class="op">=</span><span class="st">"Volume"</span>, text_ctxt<span class="op">=</span>i18n_contexts.id_sound)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>            split.prop(strip, <span class="st">"volume"</span>, text<span class="op">=</span><span class="st">""</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>            layout.use_property_split <span class="op">=</span> <span class="va">False</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>When we scrub the <strong>volume</strong> property, the function <code>BKE_sound_set_scene_sound_volume_at_frame</code> is called. For example below, sliding the <strong>volume</strong> to 1.4…</p>
<p><img src="volume1.png" class="img-fluid" alt="Volume property in Blender's video sequencer"></p>
<p>leads to the breakpoint in <code>BKE_sound_set_scene_sound_volume_at_frame</code>.</p>
<p><img src="volumecode1.png" class="img-fluid" alt="Breakpoint at BKE_sound_set_scene_sound_volume_at_frame example"></p>
<p>The <code>frame</code> variable corresponds to the location of the playhead at 2 seconds (60 frames) and 29 frames, so <strong>(60 + 29 = 89 frames)</strong>. The <code>handle</code> variable is a pointer to Audaspace’s <code>AUD_SequenceEntry</code> class, which stores the variables such as <strong>volume</strong> and <strong>pitch</strong> for a sound sequence as shown below in Audaspace’s <code>SequenceEntry.h</code>.</p>
<details>
<summary>
Code
</summary>
<pre class="{c++}"><code>    /// The animated volume.
    AnimateableProperty m_volume;

    /// The animated panning.
    AnimateableProperty m_panning;

    /// The animated pitch.
    AnimateableProperty m_pitch;

    /// The animated location.
    AnimateableProperty m_location;

    /// The animated orientation.
    AnimateableProperty m_orientation;</code></pre>
</details>
<p>The <code>BKE_sound_set_scene_sound_volume_at_frame</code> function just only makes a call to <code>AUD_SequenceEntry_setAnimationData</code> as shown below:</p>
<details>
<summary>
Code
</summary>
<pre class="{c++}"><code>void BKE_sound_set_scene_sound_volume_at_frame(void *handle,
                                               const int frame,
                                               float volume,
                                               const char animated)
{
  AUD_SequenceEntry_setAnimationData(handle, AUD_AP_VOLUME, frame, &amp;volume, animated);
}</code></pre>
</details>
<p>The function <code>AUD_SequenceEntry_setAnimationData</code> in <code>AUD_Sequence.cpp</code> looks like the following:</p>
<details>
<summary>
Code
</summary>
<pre class="{c++}"><code>AUD_API void AUD_SequenceEntry_setAnimationData(AUD_SequenceEntry* entry, AUD_AnimateablePropertyType type, int frame, float* data, char animated)
{
    AnimateableProperty* prop = (*entry)-&gt;getAnimProperty(static_cast&lt;AnimateablePropertyType&gt;(type));
    if(animated)
    {
        if(frame &gt;= 0)
            prop-&gt;write(data, frame, 1);
    }
    else
    {
        prop-&gt;write(data);
    }
}
</code></pre>
</details>
<p>And finally, below is the call stack for <code>BKE_sound_set_scene_sound_volume_at_frame</code></p>
<details>
<summary>
Call Stack
</summary>
<pre><code>Blender!BKE_sound_set_scene_sound_volume_at_frame(void*, int, float, char) (blender/source/blender/blenkernel/intern/sound.cc:1029)
Blender!blender::seq::strip_update_sound_properties(Scene const*, Strip const*) (blender/source/blender/sequencer/intern/sequencer.cc:997)
Blender!blender::seq::strip_sound_update_cb(Strip*, void*) (blender/source/blender/sequencer/intern/sequencer.cc:1083)
Blender!blender::seq::strip_for_each_recursive(ListBase*, bool (*)(Strip*, void*), void*) (blender/source/blender/sequencer/intern/iterator.cc:29)
Blender!blender::seq::for_each_callback(ListBase*, bool (*)(Strip*, void*), void*) (blender/source/blender/sequencer/intern/iterator.cc:44)
Blender!blender::seq::eval_strips(Depsgraph*, Scene*, ListBase*) (blender/source/blender/sequencer/intern/sequencer.cc:1092)
Blender!blender::deg::DepsgraphNodeBuilder::build_scene_sequencer(Scene*)::$_0::operator()(Depsgraph*) const (blender/source/blender/depsgraph/intern/builder/deg_builder_nodes.cc:2312)</code></pre>
</details>
<p>The important thing to note above is that <code>BKE_sound_set_scene_sound_volume_at_frame</code> is called by the function <code>strip_update_sound_properties</code> in <code>sequencer.cc</code>. In a future blog, I’ll likely discuss about the <code>animated</code> parameter in <code>AUD_SequenceEntry_setAnimationData</code> and have a demo program to test out, as currently, I’m not exactly sure what it does and haven’t investigated thoroughly yet!</p>
</section>
</section>
<section id="pitch" class="level2">
<h2 class="anchored" data-anchor-id="pitch">Pitch</h2>
<p>This GSOC project will primarily focus on the sound property of pitch for implementing pitch correction. In Blender, pitch is primarily affected by retiming keys, which allows you to change the playback speed of video/audio clips. However, this has the consequence of increasing the pitch when the playback speed is increased or decreasing the pitch when the playback speed is decreased. Below is an example of using retiming keys to increase the playback audio speed.</p>
<p><img src="retiming_key.png" class="img-fluid" alt="Example of using retiming keys to increase the audio playback speed by 2.27x"></p>
<p>First, the code relevant to the drawing the retiming keys onto the audio strip can be found in <code>sequencer_retiming_draw.cc</code> but I haven’t had the time look into, but I believe it is not currently not too relevant for this project.</p>
<p>Now, one of the relevant function related to the functionality of the retiming keys (and therefore pitch!) is <code>retiming_sound_animation_data_set</code> in <code>strip_retiming.cc</code> which is declared as the following:</p>
<details>
<summary>
Code
</summary>
<pre class="{c++}"><code>void retiming_sound_animation_data_set(const Scene *scene, const Strip *strip)
{
  /* Content cut off by `anim_startofs` is as if it does not exist for sequencer. But Audaspace
   * seeking relies on having animation buffer initialized for whole sequence. */
  if (strip-&gt;anim_startofs &gt; 0) {
    const int strip_start = time_start_frame_get(strip);
    BKE_sound_set_scene_sound_pitch_constant_range(
        strip-&gt;scene_sound, strip_start - strip-&gt;anim_startofs, strip_start, 1.0f);
  }

  const float scene_fps = float(scene-&gt;r.frs_sec) / float(scene-&gt;r.frs_sec_base);
  const int sound_offset = time_get_rounded_sound_offset(strip, scene_fps);

  RetimingRangeData retiming_data = strip_retiming_range_data_get(scene, strip);
  for (int i = 0; i &lt; retiming_data.ranges.size(); i++) {
    RetimingRange range = retiming_data.ranges[i];
    if (range.type == TRANSITION) {

      const int range_length = range.end - range.start;
      for (int i = 0; i &lt;= range_length; i++) {
        const int frame = range.start + i;
        BKE_sound_set_scene_sound_pitch_at_frame(
            strip-&gt;scene_sound, frame + sound_offset, range.speed_table[i], true);
      }
    }
    else {
      BKE_sound_set_scene_sound_pitch_constant_range(
          strip-&gt;scene_sound, range.start + sound_offset, range.end + sound_offset, range.speed);
    }
  }
}
</code></pre>
</details>
<p>The code above loops over retiming key ranges (which is stored in the <code>RetimingRange</code> class and contains variables like the <code>start</code> and <code>end</code> frame, the playbeed <code>speed</code>, as well as it type which is defined as an enumerator below in <code>strip_retiming.cc</code>)</p>
<pre class="{c++}"><code>enum eRangeType {
  LINEAR = 0,
  TRANSITION = 1,
};</code></pre>
<p>Additionally, <code>retiming_sound_animation_data_set</code> makes a call to two different pitch functions <code>BKE_sound_set_scene_sound_pitch_at_frame</code> and <code>BKE_sound_set_scene_sound_pitch_constant_range</code> depending on whether the range is <code>LINEAR</code> or <code>TRANSITION</code> and is defined as below in <code>sound.cc</code>:</p>
<details>
<summary>
Code
</summary>
<pre class="{c++}"><code>void BKE_sound_set_scene_sound_pitch_at_frame(void *handle,
                                              const int frame,
                                              float pitch,
                                              const char animated)
{
  AUD_SequenceEntry_setAnimationData(handle, AUD_AP_PITCH, frame, &amp;pitch, animated);
}

void BKE_sound_set_scene_sound_pitch_constant_range(void *handle,
                                                    int frame_start,
                                                    int frame_end,
                                                    float pitch)
{
  frame_start = max_ii(0, frame_start);
  frame_end = max_ii(0, frame_end);
  AUD_SequenceEntry_setConstantRangeAnimationData(
      handle, AUD_AP_PITCH, frame_start, frame_end, &amp;pitch);
}</code></pre>
</details>
<p>Below is an example of the two range types:</p>
<p><img src="retiming_range_types.png" class="img-fluid" alt="Different range types: TRANSITION and LINEAR"></p>
<p>where the <code>TRANSITION</code> range is represented by the retiming keys with <strong>77% - 116%</strong> in between while the retiming keys with <strong>77%</strong> or <strong>116%</strong> represents a <code>LINEAR</code> range. In the example image above, the <code>TRANSITION</code> range interpolates between the <strong>77%</strong> and <strong>116%</strong> playback speed from the 00:23-00:36 range. Codewise, <code>RetimingRange</code> stores the interpolated values from <strong>77% - 116%</strong> inside a vector <code>speed_table</code> which is set for which is set for each frame within the <code>TRANSITION</code> range.</p>
<p>Meanwhile, the <code>LINEAR</code> ranges (00:00-00:23 and 00:36-01:10) maintains a constant playback speed (and thus the same constant pitch for that particular playback speed).</p>
<p>Here’s an example audio clip which contains both the RetimingRanges type!</p>
<div class="quarto-video"><video id="video_shortcode_videojs_video2" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="retiming_audio_example.mp4"></video></div>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<ul>
<li>In the upcoming weeks, I will probably play around with the <code>AUD_SequenceEntry</code> class in an isolated environment to get a better sense of how it works and also mess around with the different <code>AnimateableProperty</code>s. - I currently have the Rubberband Library built as a static library in a separate, local fork, and make it public for code review this or next week. I will also take the time to understand Audaspace’s <code>Effect</code> and <code>EffectReader</code> class by looking at the many, many examples and see if I can do something with the <code>Rubberband Library</code> there</li>
<li>I also need to finish up writing the post about compiling the <code>Rubberband Library</code>, how to use it, and benchmarking it to make sure it is suitable and usable for Audaspace/Blender</li>
</ul>
</section>
<section id="questions" class="level2">
<h2 class="anchored" data-anchor-id="questions">Questions</h2>
<p>These were things/questions I wasn’t sure about Blender’s codebase or where I can access the variable from the UI in the 1st week! These were answered by Aras, which I summarized his answers below.</p>
<section id="question-1" class="level4">
<h4 class="anchored" data-anchor-id="question-1">Question #1</h4>
<p>For this line in <code>sequencer.cc</code></p>
<pre><code>BKE_sound_set_scene_sound_volume_at_frame(strip-&gt;scene_sound, frame, strip-&gt;volume, (strip-&gt;flag &amp; SEQ_AUDIO_VOLUME_ANIMATED) != 0);</code></pre>
<p>where can the strip flag be toggled for having animated volume in Blender</p>
</section>
<section id="answer-1" class="level4">
<h4 class="anchored" data-anchor-id="answer-1">Answer #1</h4>
<p>The volume property is driven by an animation f-curve or animation driver expression.</p>
<p><img src="volume_fcurve.png" class="img-fluid" alt="Example of volume being driven by f-curve"></p>
</section>
<section id="question-2" class="level4">
<h4 class="anchored" data-anchor-id="question-2">Question #2</h4>
<p>For <code>AUD_SequenceEntry_setAnimationData</code> function what exactly does the <code>animated</code> parameter do? I didn’t have time to look into further this week.</p>
</section>
<section id="answer-2" class="level4">
<h4 class="anchored" data-anchor-id="answer-2">Answer #2</h4>
<p>When the <code>animated</code> parameter is set to <code>true</code>, then it applies whatever property to that given frame. Otherwise, it sets it for that entire <code>SequenceEntry</code></p>
</section>
<section id="question-3" class="level4">
<h4 class="anchored" data-anchor-id="question-3">Question #3</h4>
For the operator types below, what editor has these operators in Blender?
<details>
<summary>
Code
</summary>
<pre class="{c++}"><code>void ED_operatortypes_sound()
{
  WM_operatortype_append(SOUND_OT_open);
  WM_operatortype_append(SOUND_OT_open_mono);
  WM_operatortype_append(SOUND_OT_mixdown);
  WM_operatortype_append(SOUND_OT_pack);
  WM_operatortype_append(SOUND_OT_unpack);
  WM_operatortype_append(SOUND_OT_update_animation_flags);
  WM_operatortype_append(SOUND_OT_bake_animation);
}</code></pre>
</details></section>
<section id="answer-3" class="level4">
<h4 class="anchored" data-anchor-id="answer-3">Answer #3</h4>
<p>It’s from “Render -&gt; Render Audio…” menu item in Blender, but the operations are not too relevant to the project</p>

</section>
</section>
<section id="random-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="random-thoughts">Random Thoughts</h2>
<ul>
<li>I learned a lot of things during this first week from things like compiling/making a blog, to learning a little bit about CMAKE files and how to read them, and to using the debugger in VSCode more efficiently and for other projects</li>
<li>I hope these notes were somewhat useful or insightful to anyone looking to understand a bit about Blender’s VSE! I know these notes will be useful for me down the line as I start to implement the pitch correction toggle, and I will have more questions down the line! This post took way longer to write than I initially thought, but I really enjoyed taking the time to understand and explain a portion of Blender’s VSE.</li>
<li>It so far seems very likely that I will not have to manually implement the pitch correction algorithm myself!</li>
<li>In the future, I will probably update this post to have more information, as I’ve just mostly touched upon areas that were relevant to the project</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<script>videojs(video_shortcode_videojs_video1);</script>
<script>videojs(video_shortcode_videojs_video2);</script>




</body></html>